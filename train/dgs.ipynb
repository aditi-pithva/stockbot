{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ceKWmmkk2hXa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "import time\n",
        "from pandas.tseries.offsets import BDay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def calculate_technical_indicators(df):\n",
        "    if len(df) < 7:\n",
        "        return None\n",
        "    features = {}\n",
        "    features['close_price'] = df['Close'].iloc[-1]\n",
        "    features['open_price'] = df['Open'].iloc[-1]\n",
        "    features['high_price'] = df['High'].iloc[-1]\n",
        "    features['low_price'] = df['Low'].iloc[-1]\n",
        "    features['volume'] = df['Volume'].iloc[-1]\n",
        "    features['daily_return'] = (df['Close'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]\n",
        "    features['weekly_return'] = (df['Close'].iloc[-1] - df['Close'].iloc[0]) / df['Close'].iloc[0]\n",
        "    features['price_momentum_3d'] = (df['Close'].iloc[-1] - df['Close'].iloc[-4]) / df['Close'].iloc[-4] if len(df) >= 4 else 0\n",
        "    features['sma_3'] = df['Close'].rolling(3).mean().iloc[-1]\n",
        "    features['sma_7'] = df['Close'].rolling(7).mean().iloc[-1] if len(df) >= 7 else df['Close'].mean()\n",
        "    features['ema_3'] = df['Close'].ewm(span=3).mean().iloc[-1]\n",
        "    features['price_to_sma3'] = df['Close'].iloc[-1] / features['sma_3']\n",
        "    features['price_to_sma7'] = df['Close'].iloc[-1] / features['sma_7']\n",
        "    features['price_volatility'] = df['Close'].pct_change().std()\n",
        "    features['high_low_ratio'] = df['High'].iloc[-1] / df['Low'].iloc[-1]\n",
        "    features['close_to_high_ratio'] = df['Close'].iloc[-1] / df['High'].iloc[-1]\n",
        "    features['close_to_low_ratio'] = df['Close'].iloc[-1] / df['Low'].iloc[-1]\n",
        "    features['volume_sma'] = df['Volume'].rolling(3).mean().iloc[-1]\n",
        "    features['volume_ratio'] = df['Volume'].iloc[-1] / features['volume_sma'] if features['volume_sma'] > 0 else 1\n",
        "    features['price_volume'] = df['Close'].iloc[-1] * df['Volume'].iloc[-1]\n",
        "    delta = df['Close'].diff()\n",
        "    gain = (delta.where(delta > 0, 0)).rolling(window=7).mean()\n",
        "    loss = (-delta.where(delta < 0, 0)).rolling(window=7).mean()\n",
        "    rs = gain / loss\n",
        "    features['rsi'] = 100 - (100 / (1 + rs.iloc[-1])) if not np.isnan(rs.iloc[-1]) and rs.iloc[-1] != 0 else 50\n",
        "    ema_12 = df['Close'].ewm(span=3).mean()\n",
        "    ema_26 = df['Close'].ewm(span=5).mean()\n",
        "    features['macd'] = (ema_12.iloc[-1] - ema_26.iloc[-1]) / df['Close'].iloc[-1]\n",
        "    sma_bb = df['Close'].rolling(5).mean()\n",
        "    std_bb = df['Close'].rolling(5).std()\n",
        "    upper_bb = sma_bb + (std_bb * 2)\n",
        "    lower_bb = sma_bb - (std_bb * 2)\n",
        "    features['bb_position'] = (df['Close'].iloc[-1] - lower_bb.iloc[-1]) / (upper_bb.iloc[-1] - lower_bb.iloc[-1]) if (upper_bb.iloc[-1] - lower_bb.iloc[-1]) != 0 else 0.5\n",
        "    recent_high = df['High'].rolling(7).max().iloc[-1]\n",
        "    recent_low = df['Low'].rolling(7).min().iloc[-1]\n",
        "    features['distance_to_high'] = (recent_high - df['Close'].iloc[-1]) / df['Close'].iloc[-1]\n",
        "    features['distance_to_low'] = (df['Close'].iloc[-1] - recent_low) / df['Close'].iloc[-1]\n",
        "    x = np.arange(len(df))\n",
        "    y = df['Close'].values\n",
        "    slope = np.polyfit(x, y, 1)[0]\n",
        "    features['trend_slope'] = slope / df['Close'].iloc[-1]\n",
        "    features['gap_up'] = max(0, (df['Open'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2]) if len(df) >= 2 else 0\n",
        "    features['gap_down'] = max(0, (df['Close'].iloc[-2] - df['Open'].iloc[-1]) / df['Close'].iloc[-2]) if len(df) >= 2 else 0\n",
        "    features['intraday_return'] = (df['Close'].iloc[-1] - df['Open'].iloc[-1]) / df['Open'].iloc[-1]\n",
        "    features['intraday_high_reach'] = (df['High'].iloc[-1] - df['Open'].iloc[-1]) / df['Open'].iloc[-1]\n",
        "    features['intraday_low_reach'] = (df['Open'].iloc[-1] - df['Low'].iloc[-1]) / df['Open'].iloc[-1]\n",
        "    up_days = (df['Close'] > df['Open']).sum()\n",
        "    features['bullish_days_ratio'] = up_days / len(df)\n",
        "    features['vpt'] = ((df['Close'].pct_change() * df['Volume']).cumsum()).iloc[-1] / df['Volume'].sum() if df['Volume'].sum() > 0 else 0\n",
        "    return features\n",
        "\n",
        "def generate_enhanced_dataset(tickers, start_date, end_date, save_path=\"enhanced_stock_features.csv\"):\n",
        "    print(f\"Generating enhanced dataset for {len(tickers)} tickers...\")\n",
        "    all_data = []\n",
        "    failed_tickers = []\n",
        "    for i, ticker in enumerate(tickers):\n",
        "        try:\n",
        "            print(f\"Processing {ticker} ({i+1}/{len(tickers)})...\")\n",
        "            for attempt in range(3):\n",
        "                try:\n",
        "                    stock = yf.Ticker(ticker)\n",
        "                    hist = stock.history(start=start_date, end=end_date)\n",
        "                    if hist.empty:\n",
        "                        raise ValueError(\"No data returned\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"Retry {attempt+1} for {ticker}: {e}\")\n",
        "                    time.sleep(1)\n",
        "            else:\n",
        "                print(f\"Failed to get data for {ticker} after 3 attempts.\")\n",
        "                failed_tickers.append(ticker)\n",
        "                continue\n",
        "            if len(hist) < 7:\n",
        "                print(f\"Insufficient data for {ticker}\")\n",
        "                failed_tickers.append(ticker)\n",
        "                continue\n",
        "            for j in range(7, len(hist)):\n",
        "                window_data = hist.iloc[j-7:j]\n",
        "                features = calculate_technical_indicators(window_data)\n",
        "                if features is None:\n",
        "                    continue\n",
        "                features['ticker'] = ticker\n",
        "                features['date'] = hist.index[j-1].strftime('%Y-%m-%d')\n",
        "                if j < len(hist) - 1:\n",
        "                    future_return = (hist['Close'].iloc[j] - hist['Close'].iloc[j-1]) / hist['Close'].iloc[j-1]\n",
        "                    if future_return > 0.02:\n",
        "                        features['label'] = 'BUY'\n",
        "                    elif future_return < -0.02:\n",
        "                        features['label'] = 'SELL'\n",
        "                    else:\n",
        "                        features['label'] = 'HOLD'\n",
        "                    all_data.append(features)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {ticker}: {e}\")\n",
        "            failed_tickers.append(ticker)\n",
        "    df = pd.DataFrame(all_data)\n",
        "    if len(df) > 0:\n",
        "        df.to_csv(save_path, index=False)\n",
        "        print(f\"Dataset saved: {save_path}\")\n",
        "        print(f\"Total samples: {len(df)}\")\n",
        "        print(f\"Features: {len(df.columns) - 3}\")\n",
        "        print(f\"Label distribution:\")\n",
        "        print(df['label'].value_counts())\n",
        "        print(f\"Failed tickers: {failed_tickers}\")\n",
        "        return df\n",
        "    else:\n",
        "        print(\"No data generated\")\n",
        "        return None\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    all_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"NVDA\", \"TSLA\", \"META\", \"BRK-B\", \"UNH\", \"JNJ\", \"JPM\", \"V\", \"PG\", \"MA\", \"HD\", \"XOM\", \"CVX\", \"LLY\", \"MRK\", \"PEP\", \"ABBV\", \"AVGO\", \"KO\", \"COST\", \"TMO\", \"WMT\", \"DIS\", \"MCD\", \"NFLX\", \"ADBE\", \"CRM\", \"PYPL\", \"INTC\", \"ORCL\", \"QCOM\", \"TXN\", \"AMD\", \"IBM\", \"HON\", \"AMGN\", \"GE\", \"CAT\", \"LOW\", \"BA\", \"GS\", \"BLK\", \"AXP\", \"DUK\", \"SO\", \"PLD\", \"CI\", \"ISRG\", \"NOW\", \"ADI\", \"MDT\", \"DHR\", \"BKNG\", \"MO\", \"BDX\", \"SYK\", \"CSCO\", \"ZTS\", \"LRCX\", \"ETN\", \"VRTX\", \"TGT\", \"APD\", \"MMC\", \"GILD\", \"CME\", \"NSC\", \"ITW\", \"DE\", \"AON\", \"SPGI\", \"ICE\", \"ADP\", \"EL\", \"ASML\", \"NXPI\", \"KLAC\", \"MU\", \"LULU\", \"MAR\", \"ROST\", \"DLTR\", \"CSX\", \"EBAY\", \"EXC\", \"ILMN\", \"WDAY\", \"TEAM\", \"ZM\", \"DOCU\", \"CDNS\", \"SNPS\", \"FTNT\", \"PANW\", \"OKTA\", \"DDOG\", \"ZS\", \"CRWD\", \"MDB\", \"BIDU\", \"NTES\", \"PDD\", \"JD\", \"BABA\", \"MELI\", \"SHOP\", \"SE\", \"ABNB\", \"ETSY\", \"RIVN\", \"LCID\", \"FSLY\", \"TWLO\", \"U\", \"COIN\", \"ROKU\", \"TTD\", \"NET\", \"WBD\", \"CHTR\", \"SPLK\", \"DOCN\", \"APP\", \"PLTR\", \"BILL\", \"TM\", \"NSANY\", \"HMC\", \"SONY\", \"VOD\", \"BP\", \"RIO\", \"BHP\", \"NTTYY\", \"BAYRY\", \"SNY\", \"AZN\", \"NVO\", \"SAP\", \"RY\", \"TD\", \"BNS\", \"ENB\", \"SU\", \"CNQ\", \"SHOP.TO\", \"BCE\", \"T.TO\", \"CM.TO\", \"BAM\", \"MFC\", \"TRP\", \"GIB\", \"L.TO\", \"BBD-B.TO\", \"MG.TO\", \"AC.TO\", \"QSR.TO\", \"ATD.TO\", \"FTS.TO\", \"NA.TO\", \"POW.TO\", \"IFC.TO\", \"SPY\", \"QQQ\", \"DIA\", \"VTI\", \"VOO\", \"ARKK\", \"XLF\", \"XLE\", \"XLK\", \"XLV\"]\n",
        "\n",
        "    end_date = datetime.today() - BDay(1)  # Last business day\n",
        "    start_date = end_date - BDay(500)      # ~2 years of business days\n",
        "\n",
        "    df = generate_enhanced_dataset(\n",
        "        tickers=all_tickers,\n",
        "        start_date=start_date.strftime('%Y-%m-%d'),\n",
        "        end_date=end_date.strftime('%Y-%m-%d'),\n",
        "        save_path=\"features_extended_2years.csv\"\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2vzAlsd2lqV",
        "outputId": "fbd4d379-a5d5-4985-fa4f-7af2f8f40ecf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating enhanced dataset for 177 tickers...\n",
            "Processing AAPL (1/177)...\n",
            "Processing MSFT (2/177)...\n",
            "Processing GOOGL (3/177)...\n",
            "Processing AMZN (4/177)...\n",
            "Processing NVDA (5/177)...\n",
            "Processing TSLA (6/177)...\n",
            "Processing META (7/177)...\n",
            "Processing BRK-B (8/177)...\n",
            "Processing UNH (9/177)...\n",
            "Processing JNJ (10/177)...\n",
            "Processing JPM (11/177)...\n",
            "Processing V (12/177)...\n",
            "Processing PG (13/177)...\n",
            "Processing MA (14/177)...\n",
            "Processing HD (15/177)...\n",
            "Processing XOM (16/177)...\n",
            "Processing CVX (17/177)...\n",
            "Processing LLY (18/177)...\n",
            "Processing MRK (19/177)...\n",
            "Processing PEP (20/177)...\n",
            "Processing ABBV (21/177)...\n",
            "Processing AVGO (22/177)...\n",
            "Processing KO (23/177)...\n",
            "Processing COST (24/177)...\n",
            "Processing TMO (25/177)...\n",
            "Processing WMT (26/177)...\n",
            "Processing DIS (27/177)...\n",
            "Processing MCD (28/177)...\n",
            "Processing NFLX (29/177)...\n",
            "Processing ADBE (30/177)...\n",
            "Processing CRM (31/177)...\n",
            "Processing PYPL (32/177)...\n",
            "Processing INTC (33/177)...\n",
            "Processing ORCL (34/177)...\n",
            "Processing QCOM (35/177)...\n",
            "Processing TXN (36/177)...\n",
            "Processing AMD (37/177)...\n",
            "Processing IBM (38/177)...\n",
            "Processing HON (39/177)...\n",
            "Processing AMGN (40/177)...\n",
            "Processing GE (41/177)...\n",
            "Processing CAT (42/177)...\n",
            "Processing LOW (43/177)...\n",
            "Processing BA (44/177)...\n",
            "Processing GS (45/177)...\n",
            "Processing BLK (46/177)...\n",
            "Processing AXP (47/177)...\n",
            "Processing DUK (48/177)...\n",
            "Processing SO (49/177)...\n",
            "Processing PLD (50/177)...\n",
            "Processing CI (51/177)...\n",
            "Processing ISRG (52/177)...\n",
            "Processing NOW (53/177)...\n",
            "Processing ADI (54/177)...\n",
            "Processing MDT (55/177)...\n",
            "Processing DHR (56/177)...\n",
            "Processing BKNG (57/177)...\n",
            "Processing MO (58/177)...\n",
            "Processing BDX (59/177)...\n",
            "Processing SYK (60/177)...\n",
            "Processing CSCO (61/177)...\n",
            "Processing ZTS (62/177)...\n",
            "Processing LRCX (63/177)...\n",
            "Processing ETN (64/177)...\n",
            "Processing VRTX (65/177)...\n",
            "Processing TGT (66/177)...\n",
            "Processing APD (67/177)...\n",
            "Processing MMC (68/177)...\n",
            "Processing GILD (69/177)...\n",
            "Processing CME (70/177)...\n",
            "Processing NSC (71/177)...\n",
            "Processing ITW (72/177)...\n",
            "Processing DE (73/177)...\n",
            "Processing AON (74/177)...\n",
            "Processing SPGI (75/177)...\n",
            "Processing ICE (76/177)...\n",
            "Processing ADP (77/177)...\n",
            "Processing EL (78/177)...\n",
            "Processing ASML (79/177)...\n",
            "Processing NXPI (80/177)...\n",
            "Processing KLAC (81/177)...\n",
            "Processing MU (82/177)...\n",
            "Processing LULU (83/177)...\n",
            "Processing MAR (84/177)...\n",
            "Processing ROST (85/177)...\n",
            "Processing DLTR (86/177)...\n",
            "Processing CSX (87/177)...\n",
            "Processing EBAY (88/177)...\n",
            "Processing EXC (89/177)...\n",
            "Processing ILMN (90/177)...\n",
            "Processing WDAY (91/177)...\n",
            "Processing TEAM (92/177)...\n",
            "Processing ZM (93/177)...\n",
            "Processing DOCU (94/177)...\n",
            "Processing CDNS (95/177)...\n",
            "Processing SNPS (96/177)...\n",
            "Processing FTNT (97/177)...\n",
            "Processing PANW (98/177)...\n",
            "Processing OKTA (99/177)...\n",
            "Processing DDOG (100/177)...\n",
            "Processing ZS (101/177)...\n",
            "Processing CRWD (102/177)...\n",
            "Processing MDB (103/177)...\n",
            "Processing BIDU (104/177)...\n",
            "Processing NTES (105/177)...\n",
            "Processing PDD (106/177)...\n",
            "Processing JD (107/177)...\n",
            "Processing BABA (108/177)...\n",
            "Processing MELI (109/177)...\n",
            "Processing SHOP (110/177)...\n",
            "Processing SE (111/177)...\n",
            "Processing ABNB (112/177)...\n",
            "Processing ETSY (113/177)...\n",
            "Processing RIVN (114/177)...\n",
            "Processing LCID (115/177)...\n",
            "Processing FSLY (116/177)...\n",
            "Processing TWLO (117/177)...\n",
            "Processing U (118/177)...\n",
            "Processing COIN (119/177)...\n",
            "Processing ROKU (120/177)...\n",
            "Processing TTD (121/177)...\n",
            "Processing NET (122/177)...\n",
            "Processing WBD (123/177)...\n",
            "Processing CHTR (124/177)...\n",
            "Processing SPLK (125/177)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$SPLK: possibly delisted; no timezone found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 1 for SPLK: No data returned\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$SPLK: possibly delisted; no timezone found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 2 for SPLK: No data returned\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:yfinance:$SPLK: possibly delisted; no timezone found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retry 3 for SPLK: No data returned\n",
            "Failed to get data for SPLK after 3 attempts.\n",
            "Processing DOCN (126/177)...\n",
            "Processing APP (127/177)...\n",
            "Processing PLTR (128/177)...\n",
            "Processing BILL (129/177)...\n",
            "Processing TM (130/177)...\n",
            "Processing NSANY (131/177)...\n",
            "Processing HMC (132/177)...\n",
            "Processing SONY (133/177)...\n",
            "Processing VOD (134/177)...\n",
            "Processing BP (135/177)...\n",
            "Processing RIO (136/177)...\n",
            "Processing BHP (137/177)...\n",
            "Processing NTTYY (138/177)...\n",
            "Processing BAYRY (139/177)...\n",
            "Processing SNY (140/177)...\n",
            "Processing AZN (141/177)...\n",
            "Processing NVO (142/177)...\n",
            "Processing SAP (143/177)...\n",
            "Processing RY (144/177)...\n",
            "Processing TD (145/177)...\n",
            "Processing BNS (146/177)...\n",
            "Processing ENB (147/177)...\n",
            "Processing SU (148/177)...\n",
            "Processing CNQ (149/177)...\n",
            "Processing SHOP.TO (150/177)...\n",
            "Processing BCE (151/177)...\n",
            "Processing T.TO (152/177)...\n",
            "Processing CM.TO (153/177)...\n",
            "Processing BAM (154/177)...\n",
            "Processing MFC (155/177)...\n",
            "Processing TRP (156/177)...\n",
            "Processing GIB (157/177)...\n",
            "Processing L.TO (158/177)...\n",
            "Processing BBD-B.TO (159/177)...\n",
            "Processing MG.TO (160/177)...\n",
            "Processing AC.TO (161/177)...\n",
            "Processing QSR.TO (162/177)...\n",
            "Processing ATD.TO (163/177)...\n",
            "Processing FTS.TO (164/177)...\n",
            "Processing NA.TO (165/177)...\n",
            "Processing POW.TO (166/177)...\n",
            "Processing IFC.TO (167/177)...\n",
            "Processing SPY (168/177)...\n",
            "Processing QQQ (169/177)...\n",
            "Processing DIA (170/177)...\n",
            "Processing VTI (171/177)...\n",
            "Processing VOO (172/177)...\n",
            "Processing ARKK (173/177)...\n",
            "Processing XLF (174/177)...\n",
            "Processing XLE (175/177)...\n",
            "Processing XLK (176/177)...\n",
            "Processing XLV (177/177)...\n",
            "Dataset saved: features_extended_2years.csv\n",
            "Total samples: 82922\n",
            "Features: 33\n",
            "Label distribution:\n",
            "label\n",
            "HOLD    65157\n",
            "BUY      9179\n",
            "SELL     8586\n",
            "Name: count, dtype: int64\n",
            "Failed tickers: ['SPLK']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy to your Google Drive\n",
        "!cp features_extended_2years.csv /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35KJlKOV-9bJ",
        "outputId": "3764ce72-b9df-4868-92aa-be3ae5295190"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLooA62P--KN",
        "outputId": "28d35769-1072-4e98-af27-088c01ca08c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh features_extended_2years.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NI_xgai_Wf5",
        "outputId": "6ff67a87-98f2-4e52-d675-207c6b4cb71d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 51M Jul 24 19:44 features_extended_2years.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp features_extended_2years.csv /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "pMWfizq4_aa5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JuU7_xrt_ejR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}